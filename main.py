
import streamlit as st
import openai
import requests
from bs4 import BeautifulSoup
import re
import os
import gspread
from google.oauth2.service_account import Credentials

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è OpenAI
openai.api_key = st.secrets["OPENAI_API_KEY"]

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è Google Sheets
GSHEET_SCOPE = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
GSHEET_CREDS = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=GSHEET_SCOPE)
GSHEET_SPREADSHEET_ID = st.secrets["GSHEET_SPREADSHEET_ID"]
gc = gspread.authorize(GSHEET_CREDS)
sh = gc.open_by_key(GSHEET_SPREADSHEET_ID)

# –°—Ç–≤–æ—Ä–∏—Ç–∏ –≤–∫–ª–∞–¥–∫—É –∑–∞ –∫–ª—é—á–æ–≤–∏–º —Å–ª–æ–≤–æ–º, —è–∫—â–æ —ó—ó –Ω–µ —ñ—Å–Ω—É—î
def get_or_create_worksheet(keyword):
    try:
        worksheet = sh.worksheet(keyword)
    except gspread.exceptions.WorksheetNotFound:
        worksheet = sh.add_worksheet(title=keyword, rows="1000", cols="20")
        worksheet.append_row(["–ù–∞–∑–≤–∞ –∫–æ–º–ø–∞–Ω—ñ—ó", "–°–∞–π—Ç", "–ü–æ—à—Ç–∞", "–¢–∏–ø", "–ö—Ä–∞—ó–Ω–∞", "–í—ñ–¥–≥—É–∫ GPT"])
    return worksheet

# –û—Ç—Ä–∏–º–∞—Ç–∏ –¥–æ–º–µ–Ω —Å–∞–π—Ç—É
def extract_homepage(url):
    match = re.search(r"(https?://[^/]+)", url)
    return match.group(1) if match else url

# –û—Ç—Ä–∏–º–∞—Ç–∏ —Ç–µ–∫—Å—Ç —ñ–∑ —Å–∞–π—Ç—É
def fetch_text_from_url(url):
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        for script in soup(["script", "style"]):
            script.decompose()
        return soup.get_text(separator=' ', strip=True)
    except Exception as e:
        return ""

# –û—Ç—Ä–∏–º–∞—Ç–∏ email –∑—ñ —Å—Ç–æ—Ä—ñ–Ω–∫–∏
def extract_email_from_url(url):
    try:
        response = requests.get(url, timeout=10)
        emails = set(re.findall(r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}", response.text))
        return list(emails)[0] if emails else "-"
    except:
        return "-"

# –ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –≤–∏—Å–Ω–æ–≤–æ–∫ GPT
def analyze_with_gpt(context, site_text, url):
    prompt = f"""
–í–∏–≤—á–∏ —Å–∞–π—Ç –∫–æ–º–ø–∞–Ω—ñ—ó –∑–∞ –∞–¥—Ä–µ—Å–æ—é: {url}.
–ö–æ–Ω—Ç–µ–∫—Å—Ç: –º–∏ –∑–∞–π–º–∞—î–º–æ—Å—å –ø—Ä–æ–¥–∞–∂–µ–º —Ä–µ–Ω—Ç–≥–µ–Ω-–ø–ª—ñ–≤–∫–∏, –±—ñ–ª—å—à–µ –Ω–∞ —Å–∞–π—Ç—ñ: {context}
1. –ß–∏ –º–æ–∂–µ –∫–æ–º–ø–∞–Ω—ñ—è –±—É—Ç–∏ –Ω–∞—à–∏–º –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∏–º –∫–ª—ñ—î–Ω—Ç–æ–º? (—Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –≤–æ–Ω–∞ –Ω–µ —î –≤–∏—Ä–æ–±–Ω–∏–∫–æ–º –ø–ª—ñ–≤–∫–∏, –∞ —Ç–∞–∫–æ–∂ –Ω–µ —î –æ—Ñ—ñ—Ü—ñ–π–Ω–∏–º –ø—Ä–µ–¥—Å—Ç–∞–≤–Ω–∏—Ü—Ç–≤–æ–º –≤–∏—Ä–æ–±–Ω–∏–∫–∞, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥ Fujifilm India).
2. –í–∏–∑–Ω–∞—á —Ö—Ç–æ —Ü—è –∫–æ–º–ø–∞–Ω—ñ—è (—Ç–∏–ø: –¥–∏—Å—Ç—Ä–∏–±'—é—Ç–æ—Ä, —Ä–µ—Å–µ–ª–µ—Ä, –∫–ª—ñ–Ω—ñ–∫–∞, –≤–∏—Ä–æ–±–Ω–∏–∫ —ñ —Ç.–¥.).
3. –í–∏–∑–Ω–∞—á –∫—Ä–∞—ó–Ω—É (–∑ –∫–æ–Ω—Ç–µ–Ω—Ç—É –∞–±–æ –∫–æ–Ω—Ç–∞–∫—Ç—ñ–≤).
4. –í–∏–∑–Ω–∞—á –ø–æ—à—Ç—É (—è–∫—â–æ —î).

–§–æ—Ä–º–∞—Ç –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ:
–ö–ª—ñ—î–Ω—Ç: –¢–∞–∫/–ù—ñ ‚Äî –∫–æ—Ä–æ—Ç–∫–µ –æ–±“ë—Ä—É–Ω—Ç—É–≤–∞–Ω–Ω—è.
–¢–∏–ø: ...
–ü–æ—à—Ç–∞: ...
–ö—Ä–∞—ó–Ω–∞: ...
"""

   try:
    completion = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "–¢–∏ –∞–Ω–∞–ª—ñ–∑—É—î—à –∫–æ–Ω—Ç–µ–Ω—Ç —Å–∞–π—Ç—É —ñ –≤–∏–∑–Ω–∞—á–∞—î—à –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∏—Ö –∫–ª—ñ—î–Ω—Ç—ñ–≤."},
            {"role": "user", "content": prompt + "\n\n–ö–æ–Ω—Ç–µ–Ω—Ç —Å–∞–π—Ç—É:\n" + site_text[:4000]}
        ]
    )
        return completion.choices[0].message.content.strip()
    except Exception as e:
        return f"–ü–æ–º–∏–ª–∫–∞: {str(e)}"

# –ü–æ–±—É–¥–æ–≤–∞ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É
st.title("üîç –ü–æ—à—É–∫ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∏—Ö –∫–ª—ñ—î–Ω—Ç—ñ–≤ —á–µ—Ä–µ–∑ Google + GPT")
keyword = st.text_input("–í–≤–µ–¥–∏ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞:")
limit = st.slider("–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤", 1, 50, 10)
start = st.number_input("–ü–æ—á–∏–Ω–∞—Ç–∏ –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É ‚Ññ", 1, 100, 1)
search_button = st.button("–ü–æ—à—É–∫")

if search_button and keyword:
    from googlesearch import search
    worksheet = get_or_create_worksheet(keyword)
    homepage_set = set([row[1] for row in worksheet.get_all_values()[1:]])

    for url in search(keyword, num_results=limit, start=start - 1):
        homepage = extract_homepage(url)
        if homepage in homepage_set:
            continue

        site_text = fetch_text_from_url(url)
        email = extract_email_from_url(url)
        gpt_response = analyze_with_gpt("https://www.xraymedem.com/", site_text, url)

        # –í–∏—Ç—è–≥—É—î–º–æ –∫–ª—é—á–æ–≤—ñ —á–∞—Å—Ç–∏–Ω–∏
        client_match = re.search(r"–ö–ª—ñ—î–Ω—Ç: (–¢–∞–∫|–ù—ñ)(.*?)\n", gpt_response)
        is_client = client_match.group(1) if client_match else "–ù—ñ"

        if is_client == "–¢–∞–∫":
            company_name = homepage.replace("https://", "").replace("http://", "").split("/")[0].replace("www.", "").split(".")[0].capitalize()
            company_type_match = re.search(r"–¢–∏–ø: (.*?)\n", gpt_response)
            company_type = company_type_match.group(1).strip() if company_type_match else "-"

            email_match = re.search(r"–ü–æ—à—Ç–∞: ([^\n]+)", gpt_response)
            email = email_match.group(1).strip() if email_match else "-"
            if "–Ω–µ –≤–∫–∞–∑–∞–Ω–æ" in email.lower() or "—ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é" in email.lower():
                email = "-"

            country_match = re.search(r"–ö—Ä–∞—ó–Ω–∞: ([^\n]+)", gpt_response)
            country = country_match.group(1).strip() if country_match else "-"
            if "–Ω–µ –≤–¥–∞–ª–æ—Å—è" in country.lower() or "–≤–∞–∂–∫–æ" in country.lower():
                country = "-"

            worksheet.append_row([company_name, homepage, email, company_type, country, gpt_response])
            st.success(f"‚úÖ –î–æ–¥–∞–Ω–æ: {company_name}")

    st.success("–ì–æ—Ç–æ–≤–æ!")
